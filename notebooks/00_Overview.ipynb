{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff537cd8",
   "metadata": {},
   "source": [
    "![Banner](https://github.com/LittleHouse75/flatiron-resources/raw/main/NevitsBanner.png)\n",
    "\n",
    "----\n",
    "\n",
    "# Ethereum Scam Address Modeling — Overview\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b1d49",
   "metadata": {},
   "source": [
    "## 1. Business problem and goal\n",
    "\n",
    "Public blockchains like Ethereum are **full of fraud**, but there is no common “master list” of scam wallets.  \n",
    "Wallet providers, exchanges, and analytics vendors each maintain their own internal lists built from:\n",
    "\n",
    "- Proprietary scam labels  \n",
    "- Ad-hoc rules and heuristics  \n",
    "- Manual investigations  \n",
    "\n",
    "These lists are expensive, incomplete, and often lag behind new scam patterns.\n",
    "\n",
    "For a **wallet provider**, this means:\n",
    "\n",
    "- Users may unknowingly send funds to **known scam addresses**  \n",
    "- The provider takes on **reputational and compliance risk**  \n",
    "- Fraud teams burn time on **manual triage** instead of deeper investigations  \n",
    "\n",
    "**Business goal (wallet-provider framing):**\n",
    "\n",
    "> Learn behavioral patterns from on-chain data so we can:\n",
    "> - Flag **high-risk destinations before a transaction is sent**\n",
    "> - Prioritize **which addresses fraud teams should review first**\n",
    "> - Maintain an **internal, adaptive scam list** without sharing proprietary labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be729190",
   "metadata": {},
   "source": [
    "## 2. Why machine learning?\n",
    "\n",
    "Ethereum emits **high-dimensional, time-dependent behavior**:\n",
    "\n",
    "- Wallet histories of sends/receives, gas usage, timing bursts, fan-in / fan-out  \n",
    "- Scam patterns that change quickly and are **non-linear**  \n",
    "\n",
    "Static rules and blacklists fall behind.\n",
    "\n",
    "Machine learning lets us:\n",
    "\n",
    "- Turn raw transactions into **address-level behavioral features**  \n",
    "- Learn **non-linear scam patterns** from labeled history  \n",
    "- **Retrain** as behavior drifts  \n",
    "- Score **new or unseen addresses** in near real time  \n",
    "\n",
    "This project tests how well that works using public data, and what breaks once we respect **time** and **dataset shift**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d467b",
   "metadata": {},
   "source": [
    "## 3. What we did: datasets and experiment views\n",
    "\n",
    "### Datasets\n",
    "\n",
    "- **Benchmark Ethereum dataset (training ground)**  \n",
    "  Public “Labeled transactions-based dataset on the Ethereum network” (~70k labeled transactions).  \n",
    "  Used to build an **address-level table** and a binary `Scam` label (1 if the address ever appears as a labeled scam).\n",
    "\n",
    "- **DFPI external evaluation dataset (reality check)**  \n",
    "  Scam wallets from a regulator (e.g., California DFPI), plus their on-chain history from Etherscan, mixed with background traffic.  \n",
    "  Used only as an **external hold-out test set**.\n",
    "\n",
    "This two-dataset setup lets us check both:\n",
    "\n",
    "- Best-case behavior on a **controlled benchmark**  \n",
    "- Whether learned patterns **transfer to regulator data**\n",
    "\n",
    "### Experiment views\n",
    "\n",
    "Across notebooks we evaluate three scenarios:\n",
    "\n",
    "1. **Random address split (i.i.d.)**  \n",
    "   Train / validate / test on addresses drawn from the **same global time span**, with no address shared across splits.\n",
    "\n",
    "2. **Time-based split (past → future)**  \n",
    "   Train / validate on addresses built from **early transactions**, test on addresses built from **later transactions**, using the same feature recipe in each window.\n",
    "\n",
    "3. **External DFPI evaluation**  \n",
    "   Take the tuned model from the random-split setting and apply it, **without retraining**, to the DFPI scam-wallet dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fecaa",
   "metadata": {},
   "source": [
    "## 4. What this means for a wallet provider (BLUF)\n",
    "\n",
    "### Random address split — feasibility on historical data\n",
    "\n",
    "When train and test come from the same distribution:\n",
    "\n",
    "- A tuned XGBoost model **separates scam vs. non-scam extremely well**  \n",
    "  - ROC AUC ≈ **0.998**, Average Precision (AP) ≈ **0.79**  \n",
    "- We can define a **small high-risk segment** where ~**80% of alerts are true scams**\n",
    "\n",
    "**Implication:**  \n",
    "Given decent labeled history and relatively stable patterns, a wallet provider can build an internal model that:\n",
    "\n",
    "- Surfaces a **short, high-yield list** of suspect addresses  \n",
    "- Great for **analyst triage** and deeper investigations  \n",
    "\n",
    "---\n",
    "\n",
    "### Time-based split — reality of deployment over time\n",
    "\n",
    "When we enforce a **past → future** setup:\n",
    "\n",
    "- Performance **drops** compared to the random split  \n",
    "- At a high-precision operating point:\n",
    "  - Precision ≈ **0.9+**\n",
    "  - Recall ≈ **0.25**, AP ≈ **0.54**\n",
    "\n",
    "**Implication:**  \n",
    "\n",
    "- You still get a **very clean alert list**, but you **miss many new scams**  \n",
    "- Scam behavior **drifts over time**; “train once and forget it” is not realistic  \n",
    "- In production you’d need:\n",
    "  - **Drift and performance monitoring**\n",
    "  - **Periodic retraining** on newer labeled data\n",
    "  - Careful choice of **precision vs. recall** based on team capacity and risk appetite  \n",
    "\n",
    "---\n",
    "\n",
    "### DFPI evaluation — transfer to regulator data\n",
    "\n",
    "When we apply the random-split model to the **DFPI scam-wallet dataset** (no retraining):\n",
    "\n",
    "- ROC AUC ≈ **0.97**, AP ≈ **0.90**  \n",
    "- Most DFPI-listed scam addresses rank **near the top**, with few benign wallets mixed in  \n",
    "\n",
    "**Implication:**  \n",
    "\n",
    "- The model is not just memorizing the benchmark dataset  \n",
    "- Behavior-based features have **real transfer value** to external, regulator-reported scams  \n",
    "- Similar features + modeling approach can likely extract **useful signals from your own data**, even with different label sources and time periods  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc4e9fa",
   "metadata": {},
   "source": [
    "## 5. How a stakeholder could use this work\n",
    "\n",
    "Even without adopting this exact codebase, the analysis maps to a concrete path for a wallet provider or exchange.\n",
    "\n",
    "### A. Data you need\n",
    "\n",
    "Most providers already have:\n",
    "\n",
    "- Raw or enriched **transaction tables** with:\n",
    "  - from / to addresses  \n",
    "  - value, gas, and fees  \n",
    "  - timestamps or block numbers  \n",
    "- Some internal notion of **“risky” or “confirmed scam”** addresses\n",
    "\n",
    "This project (plus the appendices) shows a **minimum viable schema** and field dictionary to build:\n",
    "\n",
    "- Address-level **behavioral features**  \n",
    "- Time-aware **train / validation / test** splits  \n",
    "\n",
    "---\n",
    "\n",
    "### B. How to reuse this pipeline on your data\n",
    "\n",
    "A practical adaptation plan:\n",
    "\n",
    "1. Implement an **address-level feature pipeline** similar to the one used here.  \n",
    "2. Run the same three evaluation views on your own labels:\n",
    "   - Random address split → **best-case ceiling**  \n",
    "   - Time-based split → **deployment realism**  \n",
    "   - External / cross-dataset test → **transferability** (if you have another label source)  \n",
    "3. Present curves and confusion matrices so fraud leadership sees the **precision vs. recall trade-offs** clearly.\n",
    "\n",
    "---\n",
    "\n",
    "### C. How this would look in production\n",
    "\n",
    "The experiments suggest a production setup would involve:\n",
    "\n",
    "- **Choosing thresholds** to:\n",
    "  - Produce a **small, ultra-clean analyst queue**, or  \n",
    "  - Cast a **wider net** for automated friction (warnings, extra checks)  \n",
    "- **Scheduled retraining** (e.g., monthly / quarterly) as new scams appear  \n",
    "- Simple **drift monitoring** on key features and score distributions  \n",
    "- A small **held-out recent slice** for testing new models before promotion  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4a10f3",
   "metadata": {},
   "source": [
    "## 6. Notebook roadmap — for data and ML teams\n",
    "\n",
    "Each notebook can be run independently. Together they tell the story end-to-end.\n",
    "\n",
    "### [01_EDA.ipynb — Enhanced EDA: Ethereum scam dataset](01_EDA.ipynb)\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "- Load and sanity-check the raw transaction dataset  \n",
    "- Normalize timestamps and create `block_timestamp_dt`  \n",
    "- Explore:\n",
    "  - Time coverage  \n",
    "  - Basic distributions (value, gas, etc.)  \n",
    "  - Scam vs. non-scam label balance  \n",
    "\n",
    "---\n",
    "\n",
    "### [02_RandomSplitAnalysis.ipynb — Random address split (i.i.d.)](02_RandomSplitAnalysis.ipynb)\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "- Aggregate raw transactions into **address-level features**  \n",
    "- Perform a **random address-level split** (train / validation / test)  \n",
    "- Train and tune models (focus on XGBoost) with:\n",
    "  - Metric tables  \n",
    "  - ROC / PR curves  \n",
    "  - Threshold analysis for high-precision alerting  \n",
    "\n",
    "---\n",
    "\n",
    "### [03_TimeSplitAnalysis.ipynb — Train on the past, test on the future](03_TimeSplitAnalysis.ipynb)\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "- Enforce a **past → future** scenario with a time cutoff  \n",
    "- Rebuild address-level features separately for past (train / val) and future (test)  \n",
    "- Re-run model training and thresholding under this more realistic setup  \n",
    "\n",
    "---\n",
    "\n",
    "### [04_DFPI_ExternalEval.ipynb — External evaluation on DFPI scam wallets](04_DFPI_ExternalEval.ipynb)\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "- Build an evaluation set from **regulator-reported scam wallets** (DFPI)  \n",
    "- Engineer the same behavioral features from Etherscan history  \n",
    "- Apply the tuned model from the random-split experiment **without retraining**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260ae16",
   "metadata": {},
   "source": [
    "## 7. Limitations and future directions\n",
    "\n",
    "**Key limitations**\n",
    "\n",
    "- **Label coverage:** many addresses are unlabeled; “non-scam” often just means “not tagged as scam”  \n",
    "- **Time coverage:** the benchmark dataset covers a specific historical window; newer scams may look different  \n",
    "- **Feature scope:** features are **transactional, address-level** only:\n",
    "  - No contract bytecode or ABI decoding  \n",
    "  - No graph-structure features (communities, motifs, etc.)  \n",
    "  - No off-chain signals (KYC, IPs, devices, etc.)  \n",
    "\n",
    "**Potential next steps**\n",
    "\n",
    "- Add **graph-based signals** (e.g., PageRank, communities, subgraph patterns)  \n",
    "- Incorporate **contract-level metadata** and DeFi protocol interactions  \n",
    "- Experiment with **rolling-window** or online training for drift  \n",
    "- Wrap scoring into an **analyst dashboard** for triage and investigations  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b965d7d",
   "metadata": {},
   "source": [
    "## Appendix A — Raw Ethereum transaction schema\n",
    "\n",
    "| Field | Type | Meaning | Use | Notes |\n",
    "|---|---|---|---|---|\n",
    "| hash | string | Unique transaction hash | context | Not modeled directly; can be used as row ID |\n",
    "| nonce | int | Per-sender transaction count at time of tx | dropped | Not used in current feature set |\n",
    "| transaction_index | int | Position of tx within block | dropped | Block-local ordering only |\n",
    "| from_address | string | Sender address | analysis | Used as key to build per-address features |\n",
    "| to_address | string | Recipient address | analysis | Used as key to build per-address features |\n",
    "| value | float | Transferred ETH amount in wei | analysis | Aggregated into incoming/outgoing amount features |\n",
    "| gas | int | Gas limit specified for tx | analysis | Used for avg gas limit per address |\n",
    "| gas_price | float | Gas price offered (wei per gas unit) | analysis | Used for avg gas price per address |\n",
    "| input | string | Hex calldata / payload | dropped | Not parsed in this project |\n",
    "| receipt_cumulative_gas_used | int | Total gas used in block up to this tx | dropped | Not used in current features |\n",
    "| receipt_gas_used | int | Gas used by this tx alone | dropped | Redundant with other gas behavior for this analysis |\n",
    "| block_timestamp | string → datetime | Block time for tx | analysis | Parsed to UTC; basis for all time/sequence features |\n",
    "| block_number | int | Block height containing tx | dropped | Highly collinear with timestamp; not modeled directly |\n",
    "| block_hash | string | Hash of containing block | dropped | Not used in current features |\n",
    "| from_scam | int (0/1) | Source is labeled scam address | analysis | Used to construct per-address Scam label |\n",
    "| to_scam | int (0/1) | Destination is labeled scam address | analysis | Used to construct per-address Scam label |\n",
    "| from_category | string | Labeled category for sender | analysis | Used to flag scam/fraud/phish categories |\n",
    "| to_category | string | Labeled category for recipient | analysis | Used to flag scam/fraud/phish categories |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e230c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Appendix B — Engineered address-level feature dictionary\n",
    "\n",
    "Index: each row corresponds to a unique Ethereum `Address` (string), aggregated over all transactions.\n",
    "\n",
    "| Field | Type | Meaning | Use | Notes |\n",
    "|---|---|---|---|---|\n",
    "| in_degree | int | Count of incoming txs to address | analysis | Number of rows where address is `to_address` |\n",
    "| out_degree | int | Count of outgoing txs from address | analysis | Number of rows where address is `from_address` |\n",
    "| unique in_degree | int | Number of distinct senders to this address | analysis | Unique `from_address` values seen as incoming |\n",
    "| unique out_degree | int | Number of distinct recipients from this address | analysis | Unique `to_address` values seen as outgoing |\n",
    "| Avg amount incoming | float | Mean incoming transfer value (wei) | analysis | Averaged over all txs where address is recipient |\n",
    "| Total amount incoming | float | Sum of incoming transfer value (wei) | analysis | Total ETH in wei received |\n",
    "| Max amount incoming | float | Maximum single incoming value (wei) | analysis | Largest inbound transfer |\n",
    "| Min amount incoming | float | Minimum single incoming value (wei) | analysis | Smallest inbound transfer (0 if none) |\n",
    "| Avg amount outgoing | float | Mean outgoing transfer value (wei) | analysis | Averaged over all txs sent by address |\n",
    "| Total amount outgoing | float | Sum of outgoing transfer value (wei) | analysis | Total ETH in wei sent |\n",
    "| Max amount outgoing | float | Maximum single outgoing value (wei) | analysis | Largest outbound transfer |\n",
    "| Min amount outgoing | float | Minimum single outgoing value (wei) | analysis | Smallest outbound transfer (0 if none) |\n",
    "| Avg time incoming | float | Mean timestamp of incoming txs (seconds) | analysis | Seconds since earliest block in dataset |\n",
    "| Avg time outgoing | float | Mean timestamp of outgoing txs (seconds) | analysis | Seconds since earliest block in dataset |\n",
    "| Total Tx Time | float | Sum of the actual time gaps between consecutive transactions (seconds) | analysis | For addresses with ≥2 txs, this equals the sum of all inter-transaction intervals; 0 if ≤1 tx |\n",
    "| Active Duration | float | Lifespan between first and last tx (s) | analysis | 0 if only a single tx |\n",
    "| Mean time interval | float | Mean gap between consecutive txs (s) | analysis | 0 if ≤1 tx |\n",
    "| Max time interval | float | Largest gap between consecutive txs (s) | analysis | 0 if ≤1 tx |\n",
    "| Min time interval | float | Smallest gap between consecutive txs (s) | analysis | 0 if ≤1 tx |\n",
    "| Burstiness | float | max_gap / median_gap of tx times | analysis | 0 for ≤2 txs; higher = more bursty activity |\n",
    "| Tx count | int | Total number of txs (in + out) for this address | analysis | Equals in_degree + out_degree over the dataset window |\n",
    "| Activity Density | float | Tx count per second of Active Duration | analysis | `Tx count / (Active Duration + 1)` to avoid division by zero |\n",
    "| Incoming count | int | Number of incoming txs | analysis | Count of records where address is recipient |\n",
    "| Outgoing count | int | Number of outgoing txs | analysis | Count of records where address is sender |\n",
    "| In/Out Ratio | float | (Incoming count + 1) divided by (Outgoing count + 1) | analysis | Higher values = sink-like behavior; +1 terms avoid divide-by-zero |\n",
    "| Hour mean | float | Mean hour of day of activity (0–23) | analysis | Computed from UTC timestamps across all txs |\n",
    "| Hour entropy | float | Entropy of hourly activity distribution (bits) | analysis | 0 = all txs at one hour; higher = spread across hours |\n",
    "| Last seen | float | Timestamp of most recent tx (s) | analysis | Seconds since earliest block in dataset |\n",
    "| Recency | float | How long before dataset end address was last active (s) | analysis | `dataset_end_ts_seconds − Last seen` |\n",
    "| Avg gas price | float | Mean gas price used by address (wei per gas) | analysis | Aggregated across all in/out txs |\n",
    "| Avg gas limit | float | Mean gas limit on txs involving address | analysis | Aggregated across all in/out txs |\n",
    "| Scam | int (0/1) | Address labeled as scam-related | target | Derived from from_scam/to_scam and *_category text |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
